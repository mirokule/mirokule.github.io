<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Unity, iOS, Swift, ML" />










<meta name="description" content="万人迷">
<meta property="og:type" content="website">
<meta property="og:title" content="Gate of Babylon">
<meta property="og:url" content="http://mirokule.github.io/page/2/index.html">
<meta property="og:site_name" content="Gate of Babylon">
<meta property="og:description" content="万人迷">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Gate of Babylon">
<meta name="twitter:description" content="万人迷">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://mirokule.github.io/page/2/"/>





  <title>Gate of Babylon</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Gate of Babylon</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">不积跬步，无以至千里</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            公益404
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mirokule.github.io/2018/12/08/RL-Gym/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Miles">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gate of Babylon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/08/RL-Gym/" itemprop="url">Gym</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-08T15:23:23+08:00">
                2018-12-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  548
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>OpenAI Gym由两部分组成：</p>
<ul>
<li>Gym开源库：测试问题集合（environments)，有共享的接口，允许用户设计通用算法</li>
<li>OpenAI Gym服务： 一个站点和API，允许用户对他们训练的算法进行性能比较</li>
</ul>
<h4 id="一般用法"><a href="#一般用法" class="headerlink" title="一般用法"></a>一般用法</h4><p>Gym包括几个系列的仿真环境：</p>
<ol>
<li>Classic control, Toy text：小规模任务，用于入门</li>
<li>Algorithmic：让Agent学习编程中的某些经典算法问题</li>
<li>Atari：雅达利游戏</li>
<li>2D and 3D robots: 机器人控制等</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> gym</span><br><span class="line"></span><br><span class="line">env = gym.make(<span class="string">'CartPole-v0'</span>)</span><br><span class="line">env.reset()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    env.render()</span><br><span class="line">    env.step(env.action_space.sample()) <span class="comment"># take a random action</span></span><br></pre></td></tr></table></figure>
<p>gym.make()通过id调用环境；<br>reset()初始化环境变量，重置结束标志；<br>render()将环境变量绘制到屏幕上，非必须，只是为了观察方便；<br>step()采取一步动作，返回动作后的状态、回报等。</p>
<h6 id="step-函数"><a href="#step-函数" class="headerlink" title="step()函数"></a>step()函数</h6><p>step函数有四个返回值：</p>
<ol>
<li>observation (object)：对环境的观测值的组合</li>
<li>reward (float)：上一步动作的回报</li>
<li>done (boolean)：episode是否已结束，可由reset重置</li>
<li>info (dict)：调试信息，但不能用于agent学习过程</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">action = env.action_space.sample()</span><br><span class="line">observation, reward, done, info = env.step(action)</span><br></pre></td></tr></table></figure>
<h4 id="自定义问题"><a href="#自定义问题" class="headerlink" title="自定义问题"></a>自定义问题</h4><p>除了内置的环境，也可以自定义问题环境。<br>需要实现step(), reset(), render()函数等。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#定义状态空间S</span></span><br><span class="line">self.states=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义动作空间A</span></span><br><span class="line">self.actions=[<span class="string">'n'</span>,<span class="string">'e'</span>,<span class="string">'s'</span>,<span class="string">'w'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义回报函数R</span></span><br><span class="line">self.rewards = dict()</span><br><span class="line">self.rewards[<span class="string">'1_s'</span>] = <span class="number">1.0</span></span><br><span class="line">self.rewards[<span class="string">'3_n'</span>] = <span class="number">-1.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义状态转移矩阵T</span></span><br><span class="line">self.t = dict()</span><br><span class="line">self.t[<span class="string">'2_w'</span>] = <span class="number">1</span></span><br><span class="line">self.t[<span class="string">'2_e'</span>] = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#实现step()函数,注意输入输出</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_step</span><span class="params">(self, action)</span>:</span></span><br><span class="line">    <span class="comment">#系统当前状态</span></span><br><span class="line">    state = self.state</span><br><span class="line"></span><br><span class="line">    <span class="comment">#判断系统当前状态是否为终止状态</span></span><br><span class="line">    <span class="keyword">if</span> state <span class="keyword">in</span> self.terminate_states:</span><br><span class="line">        <span class="keyword">return</span> state, <span class="number">0</span>, <span class="keyword">True</span>, &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#将状态和动作组成字典的键值</span></span><br><span class="line">    key = <span class="string">"%d_%s"</span>%(state, action) </span><br><span class="line"></span><br><span class="line">    <span class="comment">#状态转移</span></span><br><span class="line">    <span class="keyword">if</span> key <span class="keyword">in</span> self.t:</span><br><span class="line">        next_state = self.t[key]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        next_state = state</span><br><span class="line">    self.state = next_state</span><br><span class="line"></span><br><span class="line">    <span class="comment">#判断是否终止</span></span><br><span class="line">    is_terminal = <span class="keyword">False</span></span><br><span class="line">    <span class="keyword">if</span> next_state <span class="keyword">in</span> self.terminate_states:</span><br><span class="line">        is_terminal = <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#判断回报</span></span><br><span class="line">    <span class="keyword">if</span> key <span class="keyword">not</span> <span class="keyword">in</span> self.rewards:</span><br><span class="line">        r = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        r = self.rewards[key]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> next_state, r,is_terminal,&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#实现绘图函数render()</span></span><br><span class="line"><span class="comment">#略</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#实现重置函数reset()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_reset</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.state = self.states[int(random.random() * len(self.states))]</span><br><span class="line">    <span class="keyword">return</span> self.state</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mirokule.github.io/2018/11/21/RL-ImportanceSampling/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Miles">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gate of Babylon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/21/RL-ImportanceSampling/" itemprop="url">重要性采样</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-21T15:52:59+08:00">
                2018-11-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  545
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="数学期望"><a href="#数学期望" class="headerlink" title="数学期望"></a>数学期望</h4><h6 id="离散型"><a href="#离散型" class="headerlink" title="离散型"></a>离散型</h6><p>$$ E(x) = \sum_{k=1}^{\infty} x_k p_k $$</p>
<h6 id="连续型"><a href="#连续型" class="headerlink" title="连续型"></a>连续型</h6><p>$$ E(x) = \int_{-\infty}^{\infty} xf(x) dx $$</p>
<h4 id="蒙特卡洛积分"><a href="#蒙特卡洛积分" class="headerlink" title="蒙特卡洛积分"></a>蒙特卡洛积分</h4><p>假设有某个函数f(x)，无法直接求出积分<br>$$ \int_{a}^{b} f(x) dx $$</p>
<p>这个函数在[a,b]上的积分，实际上是函数曲线和x轴围成的区域的面积，记做A。<br>那么在y轴上，必然存在一个位置h，使得h、a、b围成的长方形的面积也等于A。而这个h，就是函数f(x)在作用域[a,b]上的平均值。<br>所以问题转化为如何在[a,b]上求出f(x)的平均值。<br><img src="\img\mc1.jpeg"></p>
<p>蒙特卡洛方法是，在[a,b]内取大量的随机值$x_i$，计算$f(x_i)$，然后将所有的$f(x_i)$取平均值，作为h的估计值。<br>在实际应用中，只能取到有限的值，因而误差是不可避免的。因而如何使用更少的样本数量，得到误差更小的h值，也是改进的方向之一。<br>用一个公式来概括蒙特卡洛积分：<br>$$ \int_{a}^{b} f(x)dx \approx \frac{b-a}{N} \sum_{i=1}^{N} f(x_i)$$</p>
<h4 id="重要性采样"><a href="#重要性采样" class="headerlink" title="重要性采样"></a>重要性采样</h4><p>蒙特卡洛积分是在[a,b]上均匀采样，但对于非均匀分布的函数f(x)来说，函数值大的地方对平均值的影响更大，因而我们希望能在函数值大的地方多采集一些数据。<br>例如下图f(x)是高斯分布，两边的值对积分的贡献少，黄色的采样点就可以少一些。<br><img src="/img/mc2.jpeg"></p>
<p>因而引入概率密度函数$p(x_i)$，作为采样点对最终积分的重要度权重。<br>p(x)有一个重要的特性：<br>$$ \int_{-\infty}^{\infty} p(x)dx = 1 $$<br>于是我们得到新的积分函数：<br>$$ \int_a^b f(x)dx \approx \frac{1}{N} \sum_{i=0}{N} \frac{f(x_i)}{p(x_i)}$$</p>
<p><img src="/img/ImportanceSampling.png"></p>
<p>原分布密度P(s)，采样器密度Q(x)，权重<br>$$ w_r = \frac{P^{*}(x^{(r)})}{Q^{*}(x^{(r)})} $$</p>
<p>Q(x)中x的值低于P(x)的地方，权重将大于1，得到更多的表示；<br>Q(x)中x的值高于P(x)的地方，权重将小于1，降低表示强度。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mirokule.github.io/2018/11/17/RL-TDLambda/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Miles">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gate of Babylon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/17/RL-TDLambda/" itemprop="url">TD($\lambda$)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-17T09:26:28+08:00">
                2018-11-17
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  846
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="0-n-step-TD"><a href="#0-n-step-TD" class="headerlink" title="0.n-step TD"></a>0.n-step TD</h4><p>TD方法除了之前介绍的1-step TD之外，还有一系列其他方法：<br><img src="/img/nstepTD.png"></p>
<p>n-step 的定义：<br>$$ G_{t:t+n} = R_{t+1} + \gamma R_{t+2} + \cdots + \gamma^{n-1} R_{t+n} + \gamma^n V_{t+n-1}(S_{t+n}) $$</p>
<p>迭代公式变为：<br>$$ V_{t+n}(S_t) = V_{t+n-1}(S_t) + \alpha[G_{t:t+n} - V_{t+n-1}(S_t)] $$</p>
<p>TD(0)可以看做n=1，MC可以看做n=T-t，是n取值的两种极端情况，往往不如n取中间值的结果。<br><img src="/img/n-stepError.png"></p>
<h4 id="1-Forward-lambda-return"><a href="#1-Forward-lambda-return" class="headerlink" title="1.Forward: $\lambda$-return"></a>1.Forward: $\lambda$-return</h4><p>$G_t^{\lambda}$ 将所有n-step returns $G_t^{(n)}$加权，使用权重$(1-\lambda)\lambda^{n-1}$<br>信号强度以速率$\lambda$减弱，因子(1-$\lambda$)是为了使等比数列权重的和为1.<br><img src="/img/TDWeight.png"></p>
<p>$$ G_t^{\lambda} = (1-\lambda)\sum_{n=1}^{\infty} \lambda^{n-1} G_t^{(n)} $$<br>或者写作<br>$$ G_t^{\lambda} = (1-\lambda)\sum_{n=1}^{T-t-1} \lambda^{n-1} G_{t:t+n} + \lambda^{T-t-1} G_t $$</p>
<p>迭代公式变为：<br>$$ V(S_t) \leftarrow V(S_t) + \alpha(G_t^{\lambda} - V(S_t)) $$</p>
<p>由于$G_t^{\lambda}$是对所有$G_t^{(n)}$的加权，包含将来时刻的回报$R_{t+n}$，因而要等到episode结束才能更新，和MC一样是off-line算法。<br>对当前时刻t的更新，用到了未来时刻{t+1,t+2,…,t+n}的结果，因而称作前向视角(Forward)。<br><img src="/img/ForwardView.png"></p>
<h4 id="2-Backward"><a href="#2-Backward" class="headerlink" title="2.Backward"></a>2.Backward</h4><p>Forward中，当前V(s)的更新用到了许多未来的 $\delta$; 而Backward中，当前的$\delta$作用于许多过去的V(s’)，相当于对过去的V(s’)提供了一个“未来切片”。这个“未来切片”的权重，使用<strong>资格迹</strong>(Eligibility Trace)来衡量。</p>
<p>假设当前时刻t，过往序列{$s_{t-3},s_{t-2},s_{t-1},s_t$}的权重是{$(\gamma\lambda)^3, (\gamma\lambda)^2, \gamma\lambda, 1$}。在某个episode里，序列采样到了{$s_1,s_3,s_2,s_1$}，那么{$s_1,s_2,s_3$}的权重便是{$(\gamma\lambda)^3+1, \gamma\lambda, (\gamma\lambda)^2$}，将权重的算法抽离出来：</p>
<p><img src="\img\EligibilityTrace.png"></p>
<p>资格迹是一种兼顾频率和时间的权重，对每个状态独立计算，状态每出现1次权重加1，时间每前进1格权重按一定比例衰减。用于TD($\lambda$)算法中：</p>
<ul>
<li>状态空间的每个s对应一个资格迹</li>
<li>每次更新时，更新所有的V(s)</li>
<li>更新量为资格迹乘以TD-error </li>
</ul>
<p>每次对所有V(s)更新，就能覆盖到所有过去曾出现的状态；更新量乘以资格迹，就能按时间距离衰减。用当前时刻的TD Error $\delta_t$对过去出现的状态更新，称作后向视角(Backward)。</p>
<p><img src="\img\BackwardView.png"></p>
<p>当$\lambda = 0$时，过去全部衰减，$E_t(s)=1(S_t=s)$，更新只考虑当前步，退化为TD(0);<br>当$\lambda = 1$时，只有衰减因子$\gamma$，更新量和every-visit MC相同。</p>
<p>TD($\lambda$)提供了可实用的Online算法，相比$\lambda$-return有3方面的改进：</p>
<ul>
<li>在episode的每一步都会更新，而不用等到结束</li>
<li>计算过程分布平均，而并非集中在结尾</li>
<li>适用于连续过程等没有结束的情况</li>
</ul>
<p>以Sarsa($\lambda$)为例，每个(s,a)对应一个资格迹E(s,a)，每个step中都要更新所有的Q(s,a)，更新量$\alpha\delta E(s,a)$。因为这是一种增量算法，数据按顺序依次进入，前后数据来自同一过程的关联步骤。<br>而在DQN中，训练数据从数据集里抽样，打破了前后关联性，就不需要资格迹。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mirokule.github.io/2018/11/16/RL-Temporal-Difference/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Miles">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gate of Babylon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/16/RL-Temporal-Difference/" itemprop="url">Temporal-Difference(0)时序差分方法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-16T15:02:58+08:00">
                2018-11-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  967
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>时序差分学习(Temporal-Difference Learning)是MC和DP的结合，不要求完整的episode(无需终止状态)。<br>像MC一样Sample，像DP一样bootstrapping. Bootstrapping自举，是指当前状态的值函数计算用到了后继状态的值函数。<br>本文先讨论one-step TD,即TD(0).</p>
<h3 id="1-TD-Prediction"><a href="#1-TD-Prediction" class="headerlink" title="1.TD Prediction"></a>1.TD Prediction</h3><h4 id="1-1-算法"><a href="#1-1-算法" class="headerlink" title="1.1 算法"></a>1.1 算法</h4><p>输入要评估的策略$\pi$<br>随机初始化V(s)<br>Repeat(对每个episode):<br>&emsp; 初始化S<br>&emsp; Repeat(对episode的每一步):<br>&emsp;&emsp; A ← 策略$\pi$为状态S指定的动作<br>&emsp;&emsp; 执行动作A，观察R,S’<br>&emsp;&emsp; V(s) ← V(s) + $\alpha$[R+$\gamma$V(S’)-V(S)]<br>&emsp;&emsp; S ← S’<br>&emsp; 直到S为终止状态</p>
<h4 id="1-2-比较"><a href="#1-2-比较" class="headerlink" title="1.2 比较"></a>1.2 比较</h4><p>MC：根据每次的$G_t$来更新$V(S_t)$<br>$$ V(S_t) \leftarrow V(S_t) + \alpha(G_t - V(S_t))$$</p>
<p>TD(0): 用估计值$R_{t+1} + \gamma V(S_{t+1})$代替$G_t$<br>$$ V(S_t) \leftarrow V(S_t) + \alpha(R_{t+1} + \gamma V(S_{t+1}) - V(S_t)) $$</p>
<p>TD和MC同样都是通过采样，多次实验(多个episode)来学习。<br>不同的是，TD利用了马尔科夫性质，总是收敛于最可能的马尔科夫解，因而在马尔科夫过程中表现更好。<br>MC没有利用马尔科夫性质，在非马尔科夫过程中表现更好。</p>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:center">Bootstrapping</th>
<th style="text-align:center">No Bootstrapping</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Sample</td>
<td style="text-align:center">Temporal Difference</td>
<td style="text-align:center">Monte Carlo</td>
</tr>
<tr>
<td style="text-align:left">No Sample</td>
<td style="text-align:center">Dynamic Programming</td>
<td style="text-align:center">Exhausitive Search</td>
</tr>
</tbody>
</table>
<h4 id="1-3-误差分析"><a href="#1-3-误差分析" class="headerlink" title="1.3 误差分析"></a>1.3 误差分析</h4><h6 id="Bias"><a href="#Bias" class="headerlink" title="Bias"></a>Bias</h6><p>Return $G_t = R_{t+1}+\gamma R_{t+2}+\cdots +\gamma^{T-1}R_T$ 无偏，因为期望值就是值函数的定义<br>True TD target $R_{t+1} + \gamma v_{\pi}(S_{t+1})$ 无偏，因为$v_{\pi}(S_{t+1})$是真实值，可以推导得到<br>TD target $R_{t+1} + \gamma V(S_{t+1})$ 有偏，因为$V(S_{t+1})$也是估计值</p>
<h6 id="Variance"><a href="#Variance" class="headerlink" title="Variance"></a>Variance</h6><p>Return $G_t$要等到最终状态出现，经过很多步，因而随机性大，方差很大。<br>TD target的方差比Return小得多，因为只有1步估计，引入的噪声少。</p>
<p>所以MC高方差，无偏差；TD低方差，有偏差。</p>
<h3 id="2-TD-Control"><a href="#2-TD-Control" class="headerlink" title="2.TD Control"></a>2.TD Control</h3><h4 id="2-1-On-Policy-Sarsa"><a href="#2-1-On-Policy-Sarsa" class="headerlink" title="2.1 On-Policy: Sarsa"></a>2.1 On-Policy: Sarsa</h4><p>遵循GPI框架，仍然分为两步：</p>
<ul>
<li>策略评估：使用动作值函数Q(s,a),因从(S,A)到(S’,A’)而得名</li>
<li>策略改进：仍然是$\epsilon -greedy$</li>
</ul>
<p>$$ Q(S_t,A_t) \leftarrow Q(S_t, A_t) + \alpha[R_{t+1} + \gamma\,Q(S_{t+1},a) - Q(S_t, A_t)] $$</p>
<h6 id="Q-s-a-评估"><a href="#Q-s-a-评估" class="headerlink" title="Q(s,a)评估"></a>Q(s,a)评估</h6><p>随机初始化Q(s,a)<br>Repeat(对每个episode):<br>&emsp; 初始化S<br>&emsp; 从当前策略($\epsilon -greedy$)中选择S对应的动作A<br>&emsp; Repeat(对episode的每一步):<br>&emsp;&emsp; 执行动作A，观察R,S’<br>&emsp;&emsp; 从<strong>当前策略</strong>中选择S’对应的动作A’<br>&emsp;&emsp; Q(S,A) ← Q(S,A) + $\alpha$[R+$\gamma$Q(S’,A’)-Q(S,A)]<br>&emsp;&emsp; S ← S’; A ← A’;<br>&emsp; 直到S为终止状态</p>
<h6 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h6><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(episodes):</span><br><span class="line">    state = env.reset()</span><br><span class="line">    action = epsilon_greedy_policy(state, epsilon)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        state_next, reward, done, _ = env.step(action)</span><br><span class="line">        action_next = epsilon_greedy_policy(state_next, epsilon)</span><br><span class="line">        </span><br><span class="line">        Q[state][action] += alpha*(reward + gamma*Q[state_next][action_next] - Q[state][action])</span><br><span class="line">        </span><br><span class="line">        state = state_next</span><br><span class="line">        action = action_next</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> done:</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<h4 id="2-2-Off-Policy-Q-learning"><a href="#2-2-Off-Policy-Q-learning" class="headerlink" title="2.2 Off-Policy: Q-learning"></a>2.2 Off-Policy: Q-learning</h4><ul>
<li>策略评估：行动策略采用$\epsilon-greedy$</li>
<li>策略改进：目标策略采用贪心策略，不使用$\epsilon-greedy$(和SARSA不同)，不需要Importance Sampling(和MC不同)</li>
</ul>
<p>类比DP中的Value Iteration，在更新时无视原策略，直接选用最大值，相当于默认使用贪心策略：<br>$$ Q(S_t,A_t) \leftarrow Q(S_t, A_t) + \alpha[R_{t+1} + \gamma\,\underset{a}{max}Q(S_{t+1},a) - Q(S_t, A_t)] $$</p>
<p>注意$\underset{a}{max}Q(S_{t+1}, a)$是下一个状态的Q_table里Q值最大的那个动作。</p>
<h6 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h6><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(episodes):</span><br><span class="line">    state = env.reset()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        action = epsilon_greedy_policy(state, epsilon)</span><br><span class="line">        state_next, reward, done, _ = env.step(action)</span><br><span class="line">        </span><br><span class="line">        q_max = max([ Q[state_next][a] <span class="keyword">for</span> a <span class="keyword">in</span> range(env.action_space.n) ])</span><br><span class="line">        Q[state][action] += alpha * (reward + gamma * q_max - Q[state][action])</span><br><span class="line">        </span><br><span class="line">        state = state_next</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> done:</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<h4 id="2-3-比较"><a href="#2-3-比较" class="headerlink" title="2.3 比较"></a>2.3 比较</h4><p>SARSA和Q-Learning的区别在于更新$Q(S_t, A_t)$时对$Q(S_{t+1},a)$的选择：</p>
<ul>
<li>SARSA：根据$\epsilon-greedy$策略选出的动作$Q(S_{t+1},a)$，会受到其他Q值较小的动作a影响</li>
<li>Q-Learning：Q值最大的动作$\underset{a}{max}Q(S_{t+1},a)$，不会受到其他Q值较小的动作a影响</li>
</ul>
<p>两种方法在采取行动时的策略相同，都是$\epsilon-greedy$.<br><img src="/img/SARSA-Q.png"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mirokule.github.io/2018/11/16/RL-MonteCarlo/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Miles">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gate of Babylon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/16/RL-MonteCarlo/" itemprop="url">Monte Carlo 蒙特卡罗方法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-16T14:10:59+08:00">
                2018-11-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1,100
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>有模型的策略迭代和值迭代方法都可以用广义策略迭代方法(Generalized Policy Iteration, GPI)来描述：首先对当前策略评估，然后利用值函数改进当前策略。<br>在无模型的强化学习过程中，转移概率矩阵P未知，因而不能使用Bellman方程。<br>可用的定义式：<br>$$ v_{\pi}(s) = E_{\pi}[\sum_{k=0}^{\infty}\gamma^k R_{t+k+1}\mid S_t=s] $$<br>$$ q_{\pi}(s) = E_{\pi}[\sum_{k=0}^{\infty}\gamma^k R_{t+k+1}\mid S_t=s, A_t=a] $$</p>
<p>可用的关系式：<br>$$ v_{\pi}(s) = \sum_{a\in A} \pi(a\mid s) q_{\pi}(s,a) $$</p>
<h3 id="1-Monte-Carlo-Prediction"><a href="#1-Monte-Carlo-Prediction" class="headerlink" title="1.Monte-Carlo Prediction"></a>1.Monte-Carlo Prediction</h3><p>蒙特卡罗方法直接从经验片段中学习，通过多次实验取平均值，作为回报的期望值，即$v_{\pi}(s)$.<br>只对片段化的MDP有效，即必须有终止状态。<br>计算平均值的方法有两种：</p>
<ul>
<li>First-Visit: 只统计每个episode中，首次访问该状态的回报</li>
<li>Every-Visit: 每次访问该状态的回报。</li>
</ul>
<h6 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h6><p>计数 N(s)← N(s) + 1<br>回报 S(s)← S(s) + Gt<br>均值 V(s) = S(s) / N(s)</p>
<h6 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h6><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_episode</span><span class="params">(policy, env)</span>:</span></span><br><span class="line">    states, actions, rewards = [], [], []</span><br><span class="line">    observation = env.reset()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        states.append(observation)</span><br><span class="line">        </span><br><span class="line">        action = policy(observation)</span><br><span class="line">        observation, reward, done, _ = env.step(action)</span><br><span class="line">        </span><br><span class="line">        actions.append(action)</span><br><span class="line">        rewards.append(reward)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> done:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> states, actions, rewards</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">first_visit_mc_prediction</span><span class="params">(policy, env, n_episodes)</span>:</span></span><br><span class="line">    value_table = defaultdict(float)</span><br><span class="line">    N = defaultdict(int)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(n_episodes):</span><br><span class="line">        states, actions, rewards = generate_episode(policy, env)</span><br><span class="line">        returns = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(len(states)<span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">            s = states[t]</span><br><span class="line">            r = rewards[t]</span><br><span class="line">            returns += r</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> s <span class="keyword">not</span> <span class="keyword">in</span> states[:t]: <span class="comment"># first-visit state s</span></span><br><span class="line">                N[s] += <span class="number">1</span></span><br><span class="line">                value_table[s] += (returns - value_table[s]) / N[s] <span class="comment"># Incremental</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> value_table</span><br></pre></td></tr></table></figure>
<h3 id="2-Monte-Carlo-Control"><a href="#2-Monte-Carlo-Control" class="headerlink" title="2.Monte-Carlo Control"></a>2.Monte-Carlo Control</h3><p>根据策略的数量，可以分为两种：</p>
<ul>
<li>On-policy: 采样和改进的是同一种策略，又称同策略；因为要兼顾探索，故得到的是最优策略的近似解</li>
<li>Off-policy: 采样和改进的是不同的策略，又称异策略</li>
</ul>
<h4 id="2-1-On-policy-Control"><a href="#2-1-On-policy-Control" class="headerlink" title="2.1 On-policy Control"></a>2.1 On-policy Control</h4><p>在策略改进中使用评估算法会有2个问题：</p>
<ul>
<li>仅有估计的$v_{\pi}(s)$不足以选出最优策略$q_*$：用实验直接估计q(s,a)</li>
<li>不能保证动作空间A里的每个动作a都被取到：<br>1.初始状态选用不同的(s,a)(Exploring Starts, 不够通用)；<br>2.以一定概率选择其他的动作($\epsilon-greedy$)</li>
</ul>
<h6 id="2-1-1-Monte-Carlo-ES-Exploring-Starts"><a href="#2-1-1-Monte-Carlo-ES-Exploring-Starts" class="headerlink" title="2.1.1 Monte Carlo ES(Exploring Starts)"></a>2.1.1 Monte Carlo ES(Exploring Starts)</h6><p>(1)随机选取$S_0, A_0$作为初始状态，需保证S、A空间中的每一对都有可能被选到<br>(2)遵循策略$\pi$，产生一个经验片段episode<br>(3)对片段中的每一对(s,a):<br>&emsp;&emsp; G ← (s,a)第一次出现后的回报<br>&emsp;&emsp; Returns(s,a) ← Returns(s,a) + G<br>&emsp;&emsp; Q(s,a) ← Returns(s,a)取平均值<br>(4)对片段中的每个状态s:<br>&emsp;&emsp; $\pi(s) \leftarrow argmax_a\, Q(s,a)$</p>
<p>例如原策略是(18,hit)(19,hit)(20,stick)，通过设定初始值，实验中会出现(18,stick)(19,stick)(20,hit)这些本来不会探索到的(s,a)策略。</p>
<h6 id="2-1-2-epsilon-greedy"><a href="#2-1-2-epsilon-greedy" class="headerlink" title="2.1.2 $\epsilon-greedy$"></a>2.1.2 $\epsilon-greedy$</h6><p>在初始状态中穷尽(s,a)往往是困难的，因而ES方法的应用范围有限。<br>另一种方法是在策略改进时，以概率$\epsilon$随机选取一个动作，以概率$1-\epsilon$选择贪心动作。<br>如果动作空间共有m个动作，那么策略为：<br>(1)遵循策略$\pi$产生片段episode<br>(2)对片段中的每一对(s,a):<br>&emsp;&emsp; G ← (s,a)第一次出现后的回报<br>&emsp;&emsp; Returns(s,a) ← Returns(s,a) + G<br>&emsp;&emsp; Q(s,a) ← Returns(s,a)取平均值<br>(3)对片段中的每个状态s:<br>$$ \pi (a|s) =<br>\begin{cases}<br>&amp;\epsilon / m + 1 - \epsilon \;\;\; if\, a^* = argmax\,Q(s,a) \\<br>&amp;\epsilon / m  \;\;\; otherwise<br>\end{cases} $$ </p>
<p>评估和改进的都是$\epsilon$-soft策略。<br>所谓soft策略是指，对任意状态s和动作a，有$\pi(a|s) &gt; 0$ </p>
<h4 id="2-2-Off-Policy"><a href="#2-2-Off-Policy" class="headerlink" title="2.2 Off-Policy"></a>2.2 Off-Policy</h4><p>On-policy并没有得到最优策略$\pi_*$。因为要兼顾exploration，得到的实际上是近似最优策略。<br>Off-Policy使用两个策略，用于探索、产生数据的称作behavior policy，学习改进的目标称作target policy.</p>
<h6 id="2-2-1-Importance-Sampling"><a href="#2-2-1-Importance-Sampling" class="headerlink" title="2.2.1 Importance Sampling"></a>2.2.1 Importance Sampling</h6><p>用一种简单分布(采样概率分布)来估计另一种复杂分布(原概率分布)的积分值。采样概率分布与原概率分布越接近，方差越小。<br><img src="/img/ImportanceSampling.png"></p>
<p>目标策略$\pi$为要估计的原概率分布，行动策略b作为采样概率分布。<br>重要性权重为：<br>$$ \rho_t^T = \prod_{k=t}^{T-1} \frac{\pi(A_k | S_k)}{\mu(A_k | S_k)} $$</p>
<p>对MC来说，重要性采样的方差太大。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mirokule.github.io/2018/11/16/RL-DynamicProgramming/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Miles">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gate of Babylon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/16/RL-DynamicProgramming/" itemprop="url">Dynamic Programming 动态规划算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-16T09:32:21+08:00">
                2018-11-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  840
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>MDP符合使用动态规划求解的条件，可以使用Bellman方程求解。<br>目标是求解$V^*(s)$，也就是$max\;Q(s,a)$。<br>对每个状态s，都有一个Q_table，记录了每个动作a对应的Q(s,a).<br>Q(s,a)由后续状态$V(s’)$估计，需要状态转移矩阵给出转移概率。</p>
<h4 id="Policy-Iteration"><a href="#Policy-Iteration" class="headerlink" title="Policy Iteration"></a>Policy Iteration</h4><p>两步:</p>
<ol>
<li>Policy Evatuation: 计算各状态s的v<br>给定策略$\pi$，计算每个状态s的value.<br>由于模型已知，转移概率矩阵p已知，v(s)和v(s’)的关系已知，所以可以从后向前迭代。<br>当两轮迭代的结果相差不大时，迭代结束。</li>
<li>Policy Improvement: 寻找更好的策略<br>在当前状态s采用新动作a，之后的状态继续沿用策略$\pi$，此时$\pi ‘(s)=a$.<br>如果$q_{\pi ‘}(s,a) \geq v_{\pi}(s)$则新策略更优。</li>
</ol>
<p>伪码：</p>
<table><tr><td bgcolor="#D1EEEE">1.Initialization<br>V(s) and $\pi$(s) arbitrarily for all $s \in S^+$<br><br>2.Policy Evaluation<br>Repeat<br>&emsp;&emsp; $ \Delta \leftarrow 0 $<br>&emsp;&emsp; for each $s \in S$:<br>&emsp;&emsp;&emsp;&emsp; v $\leftarrow$ V(s)<br>&emsp;&emsp;&emsp;&emsp; V(s) $\leftarrow \sum_a \pi (a\mid s) \sum_{s’,r} p(s’,r\mid s,a)[r+\gamma V(s’)]$<br>&emsp;&emsp;&emsp;&emsp; $\Delta \leftarrow max(\Delta, \left |v - V(s)\right|)$<br>until $\Delta &lt; \theta$<br><br>3.Policy Improvement<br>&emsp;&emsp; policy-stable $\leftarrow$ true<br>&emsp;&emsp; For each $s \in S$:<br>&emsp;&emsp;&emsp;&emsp; old-action $\leftarrow \pi(s)$<br>&emsp;&emsp;&emsp;&emsp; $\pi(s) \leftarrow argmax_a\sum_{s’,r}p(s’,r\mid s,a)[r+\gamma V(s’)]$<br>&emsp;&emsp;&emsp;&emsp; if old-action $neq \pi(s)$, then policy-stable $\leftarrow$ false<br>&emsp;&emsp; if policy-stable, then stop and return V $\approx v_<em>$ and $\pi \approx \pi_</em>$;<br>&emsp;&emsp; else go to 2<br></td></tr></table>

<p>实现：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">policy_evaluation</span><span class="params">(policy, gamma=<span class="number">1.0</span>)</span>:</span></span><br><span class="line">    value_table = np.zeros(env.nS)</span><br><span class="line">    threshold = <span class="number">1e-10</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        updated_value_table = np.copy(value_table)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> state <span class="keyword">in</span> range(env.nS):</span><br><span class="line">            action = policy[state]</span><br><span class="line">            value_table[state] = sum([ trans_prob * (reward_prob + gamma * updated_value_table[next_state])</span><br><span class="line">                                      <span class="keyword">for</span> trans_prob, next_state, reward_prob, _ <span class="keyword">in</span> env.P[state][action] ])</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> (np.sum((np.fabs(updated_value_table - value_table))) &lt;= threshold):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> value_table</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_policy</span><span class="params">(value_table, gamma=<span class="number">1.0</span>)</span>:</span></span><br><span class="line">    policy = np.zeros(env.observation_space.n)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> state <span class="keyword">in</span> range(env.observation_space.n): <span class="comment">#16个</span></span><br><span class="line">        Q_table = np.zeros(env.action_space.n) <span class="comment">#4个</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> action <span class="keyword">in</span> range(env.action_space.n):</span><br><span class="line">            <span class="keyword">for</span> next_sr <span class="keyword">in</span> env.P[state][action]:</span><br><span class="line">                trans_prob, next_state, reward_prob, _ = next_sr</span><br><span class="line">                Q_table[action] += (trans_prob * (reward_prob + gamma * value_table[next_state]))</span><br><span class="line">                </span><br><span class="line">        policy[state] = np.argmax(Q_table)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> policy</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">policy_iteration</span><span class="params">(env, gamma=<span class="number">1.0</span>)</span>:</span></span><br><span class="line">    random_policy = np.zeros(env.observation_space.n)</span><br><span class="line">    no_of_iterations = <span class="number">20000</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(no_of_iterations):</span><br><span class="line">        new_value_function = computer_value_function(random_policy, gamma)</span><br><span class="line">        new_policy = extract_policy(new_value_function, gamma)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(np.all(random_policy == new_policy)):</span><br><span class="line">            print(<span class="string">'Policy-Iteration converged at step %d.'</span> %(i+<span class="number">1</span>))</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">            </span><br><span class="line">        random_policy = new_policy</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> new_policy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用</span></span><br><span class="line">print(policy_iteration(env))</span><br></pre></td></tr></table></figure></p>
<h4 id="Value-Iteration"><a href="#Value-Iteration" class="headerlink" title="Value Iteration"></a>Value Iteration</h4><p>将policy evaluation和improvement整合到一步动作中，节约了大量计算。<br>在更新V(s)时不是取加权和，而是取最大值。相当于挑选出最优动作，然后取最优动作的q值。</p>
<p>伪码：</p>
<table><tr><td bgcolor="#D1EEEE">Initialize array V arbitratily<br>Repeat<br>&emsp;&emsp; $\Delta \leftarrow 0 $<br>&emsp;&emsp; for each $s \in S$:<br>&emsp;&emsp;&emsp;&emsp; v $\leftarrow$ V(s)<br>&emsp;&emsp;&emsp;&emsp; V(s) $\leftarrow \max_a\sum_{s’,r} p(s’,r\mid s,a)[r+\gamma V(s’)]$<br>&emsp;&emsp;&emsp;&emsp; $\Delta \leftarrow max(\Delta, \left |v - V(s)\right|)$<br><br>Output a deterministic policy, $\pi \approx \pi_*$, such that<br>$\pi(s) = argmax_a \sum_{s’,r} p(s’,r\mid s,a)[r+\gamma V(s’)]$<br></td></tr></table>

<p>实现：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">value_iteration</span><span class="params">(env, gamma=<span class="number">1.0</span>)</span>:</span></span><br><span class="line">    value_table = np.zeros(env.observation_space.n)</span><br><span class="line">    no_of_iterations = <span class="number">10000</span></span><br><span class="line">    threshold = <span class="number">1e-20</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(no_of_iterations):</span><br><span class="line">        updated_value_table = np.copy(value_table)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> state <span class="keyword">in</span> range(env.action_space.n):</span><br><span class="line">            Q_value = []</span><br><span class="line">            <span class="keyword">for</span> action <span class="keyword">in</span> range(env.action_space.n):</span><br><span class="line">                next_states_rewards = []</span><br><span class="line">                <span class="keyword">for</span> next_sr <span class="keyword">in</span> env.P[state][action]:</span><br><span class="line">                    trans_prob, next_state, reward_prob, _ = next_sr</span><br><span class="line">                    next_states_rewards.append((transprob*(reward_prob + gamma * updated_value_table[next_state]))) <span class="comment">#当前动作的所有后继状态</span></span><br><span class="line">                Q_value.append(np.sum(next_states_rewards))</span><br><span class="line">            value_table[state] = max(Q_value) <span class="comment">#取最大值，而不是求和</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (np.sum(np.fabs(updated_value_table - value_table)) &lt;= threshold):</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">'Value-iteration converged at iteration %d.'</span> %(i+<span class="number">1</span>))</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> value_table</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_policy</span><span class="params">(value_table, gamma=<span class="number">1.0</span>)</span>:</span></span><br><span class="line">    policy = np.zeros(env.observation_space.n)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> state <span class="keyword">in</span> range(env.observation_space.n): <span class="comment">#16个</span></span><br><span class="line">        Q_table = np.zeros(env.action_space.n) <span class="comment">#4个</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> action <span class="keyword">in</span> range(env.action_space.n):</span><br><span class="line">            <span class="keyword">for</span> next_sr <span class="keyword">in</span> env.P[state][action]:</span><br><span class="line">                trans_prob, next_state, reward_prob, _ = next_sr</span><br><span class="line">                Q_table[action] += (trans_prob * (reward_prob + gamma * value_table[next_state]))</span><br><span class="line">                </span><br><span class="line">        policy[state] = np.argmax(Q_table)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> policy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用</span></span><br><span class="line">optimal_value_function = value_iteration(env=env, gama=<span class="number">1.0</span>)</span><br><span class="line">optimal_policy = extract_policy(optimal_value_function, gamma=<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">print(optimal_policy)</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mirokule.github.io/2018/11/13/RL-Markov/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Miles">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gate of Babylon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/13/RL-Markov/" itemprop="url">强化学习的马尔科夫描述</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-13T15:47:47+08:00">
                2018-11-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  819
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h4><ol>
<li><p>马尔科夫性质<br>系统的下一个状态$s_{t+1}$仅与$s_t$有关，而与之前的状态都无关，称作马尔科夫性质。<br>$$ P[s_{t+1}\mid s_t] = P[s_{t+1}\mid s_1,\cdots,s_t]$$</p>
</li>
<li><p>马尔科夫过程<br>马尔科夫过程是一个二元组(S,P)，其中S是有限状态集合，P是状态转移概率。<br>转移到$s_{t+1}$的概率P仅与当前状态$s_t$有关，即满足马尔科夫性质。<br>从某个状态出发，可能有多个马尔科夫链。</p>
</li>
<li><p>马尔科夫决策过程<br>引入动作和奖励。<br>马尔科夫决策过程由元组(S,A,P,R,$\gamma$)描述。其中A是有限的动作集，R是回报函数，$\gamma$是折扣因子。</p>
</li>
</ol>
<h4 id="函数定义"><a href="#函数定义" class="headerlink" title="函数定义"></a>函数定义</h4><h6 id="1-策略-pi"><a href="#1-策略-pi" class="headerlink" title="1.策略$\pi$"></a>1.策略$\pi$</h6><p>从状态到动作的映射，即给定状态s时，指定动作概率，也就是动作集A的一个分布。<br>$$ \pi(a\mid s) = p[A_t = a\mid S_t = s] $$</p>
<p>如果策略$\pi$是确定的，那么该策略在每个状态s指定唯一确定的动作a。</p>
<h6 id="2-回报R"><a href="#2-回报R" class="headerlink" title="2.回报R"></a>2.回报R</h6><p>从每个状态s离开时，立即得到的回报r.<br>累积回报：从当前时刻起，将后续每个时刻的估计回报叠加。折扣因子$\gamma$可以避免死循环，同时由于对未来估计的不确定性，离当前时刻越远的估计回报越要打折。<br>$$ G_t = R_{t+1} + \gamma R_{t+2} + \cdots = \sum_{k=0}^{\infty} \gamma^k R_{t+k+1} $$</p>
<p>如果策略不是确定的，那么未来某个状态s可能采取不同的动作a，得到的r就不同。因而$G_t$也不是确定的，而是一种分布。</p>
<h6 id="3-状态值函数v"><a href="#3-状态值函数v" class="headerlink" title="3.状态值函数v"></a>3.状态值函数v</h6><p>$G_t$在状态s处的期望值。<br>$$ v_{\pi}(s) = E_{\pi}[\sum_{k=0}^{\infty}\gamma^k R_{t+k+1} \mid S_t=s] $$</p>
<p>状态值函数与策略是对应的，不同策略的状态值函数不同。</p>
<h6 id="4-状态-行为值函数q"><a href="#4-状态-行为值函数q" class="headerlink" title="4.状态-行为值函数q"></a>4.状态-行为值函数q</h6><p>每对(状态，动作)回报的期望值。<br>$$ q_{\pi}(s,a) = E_{\pi}[\sum_{k=0}^{\infty}\gamma^k R_{t+k+1} \mid S_t=s, A_t=a] $$</p>
<h4 id="贝尔曼方程"><a href="#贝尔曼方程" class="headerlink" title="贝尔曼方程"></a>贝尔曼方程</h4><p>实际计算和编程时，不使用上述定义式，而是用推导形式的Bellman方程：<br>$$ v_{\pi}(s) = E[R_{t+1} + \gamma v_{\pi}(S_{t+1})\mid S_t=s] $$<br>$$ q_{\pi}(s,a) = E[R_{t+1} + \gamma q_{\pi}(S_{t+1}, A_{t+1})\mid S_t=s, A_t=a] $$</p>
<p>推导过程：<br>$$ v_{\pi}(s) = \sum_{a\in A} \pi(a\mid s) q_{\pi}(s,a) $$<br>$$ q_{\pi}(s,a) = R_s^a + \gamma\sum_{s’\in S}P_{ss’}^a v_{\pi}(s’) $$<br>$$ v_{\pi}(s) = \sum_{a\in A} \pi(a\mid s) (R_s^a + \gamma\sum_{s’\in S}P_{ss’}^a v_{\pi}(s’)) $$<br>$$ q_{\pi}(s,a) = R_s^a + \gamma\sum_{s’\in S}P_{ss’}^a \sum_{a’\in A} \pi(a’\mid s’) q_{\pi}(s’,a’) $$</p>
<h4 id="最优值"><a href="#最优值" class="headerlink" title="最优值"></a>最优值</h4><p>在所有策略中最大的值函数是最优状态值函数：<br>$$ v^*(s) = \underset{\pi}{max}\, v_{\pi}(s) $$</p>
<p>在所有策略中最大的状态-行为值函数是最优状态-行为值函数：<br>$$ q^*(s,a) = \underset{\pi}{max}\, q_{\pi}(s,a) $$</p>
<p>若已知最优状态-动作值函数，则最优策略可以通过最大化$q(s,a)$来决定。<br>所以计算过程的目的是找到$q^*(s,a)$，从而达到寻找最优策略的最终目标。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mirokule.github.io/2018/09/19/Unity-MLAgents/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Miles">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gate of Babylon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/19/Unity-MLAgents/" itemprop="url">ML-Agents Toolkit</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-19T15:28:31+08:00">
                2018-09-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  385
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>ML-Agents Toolkit是Unity推出的机器学习组件，可用来训练游戏AI。<br>训练算法包括强化学习、模仿学习等。</p>
<p><img src="/img/ml-agents.png"></p>
<p>ML-Agents主要包括以下几个部分：</p>
<ul>
<li>Learning Enviroment: 包括游戏场景和角色<ul>
<li>Agents: 绑在GameObject上，给出观测并执行动作；必须对应1个Brain</li>
<li>Brains: 拥有策略，接收观测值并给出动作；可以对应多个Agents</li>
<li>Academy: 控制全局变量，安排Brain更新顺序</li>
</ul>
</li>
<li>Python API: 包括训练过程的算法，独立于Unity</li>
<li>External Communicator: 用于上述两部分的沟通</li>
</ul>
<h6 id="Brain类型"><a href="#Brain类型" class="headerlink" title="Brain类型"></a>Brain类型</h6><ul>
<li>External: 策略由外部的python API输入</li>
<li>Internal: 策略由内部的TF Model决定</li>
<li>Player: 策略由玩家用键盘鼠标输入</li>
<li>Heuristic: 策略由硬编码决定；可用于测试、对比等</li>
</ul>
<h6 id="TensorFlowSharp"><a href="#TensorFlowSharp" class="headerlink" title="TensorFlowSharp"></a>TensorFlowSharp</h6><p>TensorFlow并不支持Unity使用的C#语言，故训练好的Brain并不能直接在Unity中使用，而需要通过插件TensorFlowSharp来调用。</p>
<h4 id="训练方式"><a href="#训练方式" class="headerlink" title="训练方式"></a>训练方式</h4><p>ML-Agents提供多种训练Brain的方法。</p>
<h6 id="1-Built-in-Training-and-Inference"><a href="#1-Built-in-Training-and-Inference" class="headerlink" title="1.Built-in Training and Inference"></a>1.Built-in Training and Inference</h6><p>最常用的两步法：</p>
<ul>
<li>Training：构建训练场景，指定Brain为”External”，使python API可以调用该场景。训练得到Brain文件(TF Model)。</li>
<li>Inference：在任意场景中使用训练好的Brain文件，指定Brain模式”Internal”，需要TensorFlowSharp插件。</li>
</ul>
<h6 id="2-Custom-Training-and-Inference"><a href="#2-Custom-Training-and-Inference" class="headerlink" title="2.Custom Training and Inference"></a>2.Custom Training and Inference</h6><p>自定义Training和Inference过程的算法。<br>两步中Brain都为”External”，通过Python API控制。</p>
<h6 id="3-Curriculum-Learning"><a href="#3-Curriculum-Learning" class="headerlink" title="3.Curriculum Learning"></a>3.Curriculum Learning</h6><p>渐进地学习复杂环境下的策略</p>
<h6 id="4-Imitation-Learning"><a href="#4-Imitation-Learning" class="headerlink" title="4.Imitation Learning"></a>4.Imitation Learning</h6><p>模仿学习，通过模仿现有的例子来生成策略。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mirokule.github.io/2018/08/28/ML-ErrorSource/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Miles">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gate of Babylon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/28/ML-ErrorSource/" itemprop="url">两种模型误差</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-28T15:30:08+08:00">
                2018-08-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  272
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>机器学习问题中，模型的误差有2个来源：</p>
<ul>
<li>Bias</li>
<li>Variance</li>
</ul>
<p>低阶模型的误差主要来自bias，高阶模型的误差主要来自variance.<br><img src="/img/error_total.png"></p>
<h4 id="Bias"><a href="#Bias" class="headerlink" title="Bias"></a>Bias</h4><p>模型空间不包括真实的数据关系，因为使用模型预测得到的结果与真实数据有偏差，也就是UnderFitting。<br><img src="/img/bias_1.png"></p>
<p>对每一批数据，训练出的模型集中；<br>多个模型的均值仍与真实分布有偏差。<br><img src="/img/bias_2.png"></p>
<p>这说明模型过于简单，不能反映相对复杂的数据关系。</p>
<h4 id="Variance"><a href="#Variance" class="headerlink" title="Variance"></a>Variance</h4><p>模型空间包括真实的数据关系，但对每一批数据，训练出的模型差异较大，对测试数据的扩展能力弱，也就是UnderFitting.<br><img src="/img/variance_1.png"></p>
<p>多个模型的均值能较好地贴合真实数据分布。<br><img src="/img/variance_2.png"></p>
<p>这说明模型过于复杂，不但学到了数据分布的规律，也学到了噪声。<br>因而解决方法有：</p>
<ul>
<li>降低模型复杂度，降低学习能力</li>
<li>引入更多数据，让模型学到更多的数据分布规律而不是噪声</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mirokule.github.io/2018/07/12/ML-LightGBM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Miles">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gate of Babylon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/12/ML-LightGBM/" itemprop="url">LightGBM</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-12T16:22:29+08:00">
                2018-07-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  724
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>LightGBM全称是Light Gradient Boosting Machine，是一个基于决策树算法的分布式高性能GB框架。</p>
<h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><p>和之前的GBM框架相比，主要改进如下：</p>
<h6 id="Histogram"><a href="#Histogram" class="headerlink" title="Histogram"></a>Histogram</h6><p>现有的GBDT工具基本都是基于预排序(pre-sorted)的算法(如XGBoost)，不能用类似mini batch的方式来训练，需要对数据多次遍历。<br>LightGBM使用的是hitogram算法，将连续的特征值分桶装进离散的箱子(bins)，占用内存更少。</p>
<h6 id="Leaf-wise-tree-growth"><a href="#Leaf-wise-tree-growth" class="headerlink" title="Leaf_wise tree growth"></a>Leaf_wise tree growth</h6><p>现有工具大多数使用按层生长(level-wise)的决策树生长策略。<br>LightGBM采用了对增益最大的节点深入分解的方法(leaf-wise)，能产生更复杂的树，从而使得精度更高。<br>有时会过拟合，需要通过设置max-depth参数来避免。<br><img src="\img\level_wise.png"><br><img src="\img\leaf_wise.png"></p>
<h6 id="其他优化"><a href="#其他优化" class="headerlink" title="其他优化"></a>其他优化</h6><ol>
<li>类别特征支持，不再需要one-hot编码</li>
<li>cache访问优化</li>
<li>多线程优化</li>
<li>稀疏特征优化</li>
<li>其他</li>
</ol>
<h4 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h4><h6 id="核心参数"><a href="#核心参数" class="headerlink" title="核心参数"></a>核心参数</h6><ol>
<li>boosting_type: 默认是gbdt，其他如rf, dart, doss等</li>
<li>num_thread: 指定线程的个数</li>
<li>objective: 任务目标默认regression，其他如binary, multi-class, cross-entropy等</li>
<li>valid: 验证集</li>
<li>learning_rate: 学习率，梯度下降的步长</li>
<li>num_leaves: 一棵树上的叶子数</li>
<li>device: 默认CPU，可选GPU</li>
</ol>
<h6 id="学习控制参数"><a href="#学习控制参数" class="headerlink" title="学习控制参数"></a>学习控制参数</h6><ol>
<li>feature_fraction: 如果小于1(比如0.8)，将会在每棵树训练之前选取部分(80%)特征；可以加速训练，减少过拟合</li>
<li>bagging_fraction:</li>
<li>bagging_freq: 默认0，禁用bagging; 设置k意味着每k次迭代执行bagging</li>
<li>lambda_l1, lambda_l2: 默认0，表示L1, L2正则化</li>
</ol>
<h4 id="代码实例"><a href="#代码实例" class="headerlink" title="代码实例"></a>代码实例</h4><ol>
<li><p>应用</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train = lgb.Dataset(train_df[columns_to_use],y ,feature_name = <span class="string">"auto"</span>)</span><br><span class="line"></span><br><span class="line">params = &#123;<span class="string">'boosting_type'</span>: <span class="string">'gbdt'</span>, </span><br><span class="line">          <span class="string">'objective'</span>: <span class="string">'regression'</span>, </span><br><span class="line">          <span class="string">'metric'</span>: <span class="string">'rmse'</span>, </span><br><span class="line">          <span class="string">'learning_rate'</span>: <span class="number">0.01</span>, </span><br><span class="line">          <span class="string">'num_leaves'</span>: <span class="number">100</span>, </span><br><span class="line">          <span class="string">'feature_fraction'</span>: <span class="number">0.4</span>, </span><br><span class="line">          <span class="string">'bagging_fraction'</span>: <span class="number">0.6</span>, </span><br><span class="line">          <span class="string">'max_depth'</span>: <span class="number">5</span>, </span><br><span class="line">          <span class="string">'min_child_weight'</span>: <span class="number">10</span>&#125;</span><br><span class="line"></span><br><span class="line">clf = lgb.train(params, train, num_boost_round = <span class="number">400</span>, verbose_eval=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">preds = clf.predict(test_df[columns_to_use])</span><br></pre></td></tr></table></figure>
</li>
<li><p>GridSearch调参</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"><span class="keyword">from</span> sklearn.grid_search <span class="keyword">import</span> GridSearchCV  <span class="comment"># Perforing grid search</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train.csv'</span>)   <span class="comment"># 读取数据</span></span><br><span class="line">y = train_data.pop(<span class="string">'30'</span>).values   <span class="comment"># 用pop方式将训练数据中的标签值y取出来，作为训练目标，这里的‘30’是标签的列名</span></span><br><span class="line">col = train_data.columns   </span><br><span class="line">x = train_data[col].values  <span class="comment"># 剩下的列作为训练数据</span></span><br><span class="line">train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=<span class="number">0.333</span>, random_state=<span class="number">0</span>)   <span class="comment"># 分训练集和验证集</span></span><br><span class="line">train = lgb.Dataset(train_x, train_y)</span><br><span class="line">valid = lgb.Dataset(valid_x, valid_y, reference=train)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">parameters = &#123;</span><br><span class="line">              <span class="string">'max_depth'</span>: [<span class="number">15</span>, <span class="number">20</span>, <span class="number">25</span>, <span class="number">30</span>, <span class="number">35</span>],</span><br><span class="line">              <span class="string">'learning_rate'</span>: [<span class="number">0.01</span>, <span class="number">0.02</span>, <span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.15</span>],</span><br><span class="line">              <span class="string">'feature_fraction'</span>: [<span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">0.95</span>],</span><br><span class="line">              <span class="string">'bagging_fraction'</span>: [<span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">0.95</span>],</span><br><span class="line">              <span class="string">'bagging_freq'</span>: [<span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">8</span>],</span><br><span class="line">              <span class="string">'lambda_l1'</span>: [<span class="number">0</span>, <span class="number">0.1</span>, <span class="number">0.4</span>, <span class="number">0.5</span>, <span class="number">0.6</span>],</span><br><span class="line">              <span class="string">'lambda_l2'</span>: [<span class="number">0</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">35</span>, <span class="number">40</span>],</span><br><span class="line">              <span class="string">'cat_smooth'</span>: [<span class="number">1</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">20</span>, <span class="number">35</span>]</span><br><span class="line">&#125;</span><br><span class="line">gbm = lgb.LGBMClassifier(boosting_type=<span class="string">'gbdt'</span>,</span><br><span class="line">                         objective = <span class="string">'binary'</span>,</span><br><span class="line">                         metric = <span class="string">'auc'</span>,</span><br><span class="line">                         verbose = <span class="number">0</span>,</span><br><span class="line">                         learning_rate = <span class="number">0.01</span>,</span><br><span class="line">                         num_leaves = <span class="number">35</span>,</span><br><span class="line">                         feature_fraction=<span class="number">0.8</span>,</span><br><span class="line">                         bagging_fraction= <span class="number">0.9</span>,</span><br><span class="line">                         bagging_freq= <span class="number">8</span>,</span><br><span class="line">                         lambda_l1= <span class="number">0.6</span>,</span><br><span class="line">                         lambda_l2= <span class="number">0</span>)</span><br><span class="line"><span class="comment"># 有了gridsearch我们便不需要fit函数</span></span><br><span class="line">gsearch = GridSearchCV(gbm, param_grid=parameters, scoring=<span class="string">'accuracy'</span>, cv=<span class="number">3</span>)</span><br><span class="line">gsearch.fit(train_x, train_y)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Best score: %0.3f"</span> % gsearch.best_score_)</span><br><span class="line">print(<span class="string">"Best parameters set:"</span>)</span><br><span class="line">best_parameters = gsearch.best_estimator_.get_params()</span><br><span class="line"><span class="keyword">for</span> param_name <span class="keyword">in</span> sorted(parameters.keys()):</span><br><span class="line">    print(<span class="string">"t%s: %r"</span> % (param_name, best_parameters[param_name]))</span><br></pre></td></tr></table></figure>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mirokule.github.io/2018/07/12/Python-ToolBox/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Miles">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gate of Babylon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/12/Python-ToolBox/" itemprop="url">iPython常用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-12T14:36:18+08:00">
                2018-07-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  251
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="Import"><a href="#Import" class="headerlink" title="Import"></a>Import</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> describe</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br></pre></td></tr></table></figure>
<h4 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df_train = pd.read_csv(<span class="string">'./input/train.csv'</span>)</span><br><span class="line">df_train.shape</span><br><span class="line">df_train.head()</span><br><span class="line">df_train.info()</span><br><span class="line">df_train.describe()</span><br></pre></td></tr></table></figure>
<h4 id="绘图"><a href="#绘图" class="headerlink" title="绘图"></a>绘图</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># hist</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">5</span>))</span><br><span class="line">plt.hist(train_df.target.values, bins=<span class="number">100</span>)</span><br><span class="line">plt.title(<span class="string">'Histogram target counts'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Count'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Target'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># violin</span></span><br><span class="line">sns.set_style(<span class="string">"whitegrid"</span>)</span><br><span class="line">sns.violinplot(x=np.log1p(df_train.target.values))</span><br></pre></td></tr></table></figure>
<h4 id="运算"><a href="#运算" class="headerlink" title="运算"></a>运算</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 取Log</span></span><br><span class="line">target_log = np.log1p(df_train[<span class="string">'target'</span>].values)</span><br><span class="line">target_lgo = np.log(<span class="number">1</span>+df_train[<span class="string">'target'</span>].values)</span><br></pre></td></tr></table></figure>
<h4 id="常数列"><a href="#常数列" class="headerlink" title="常数列"></a>常数列</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 发现</span></span><br><span class="line">constant_train = train_df.loc[:, (train_df == train_df.iloc[<span class="number">0</span>]).all()].columns.tolist()</span><br><span class="line">constant_test = test_df.loc[:, (test_df == test_df.iloc[<span class="number">0</span>]).all()].columns.tolist()</span><br><span class="line">print(<span class="string">'Number of constant columns in the train set:'</span>, len(constant_train))</span><br><span class="line">print(<span class="string">'Number of constant columns in the test set:'</span>, len(constant_test))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除</span></span><br><span class="line">columns_to_use = test_df.columns.tolist()</span><br><span class="line">columns_to_use = [x <span class="keyword">for</span> x <span class="keyword">in</span> columns_to_use <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> constant_train] <span class="comment">#Remove all 0 columns</span></span><br><span class="line">len(columns_to_use)</span><br></pre></td></tr></table></figure>
<h4 id="非零项"><a href="#非零项" class="headerlink" title="非零项"></a>非零项</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 全部0计数</span></span><br><span class="line">(df_train[columns_to_use].values.flatten() == <span class="number">0</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按列0计数</span></span><br><span class="line">train_zeros = pd.DataFrame(&#123;<span class="string">'Percentile'</span>:((train_df[columns_to_use].values)==<span class="number">0</span>).mean(axis=<span class="number">0</span>),</span><br><span class="line">                           <span class="string">'Column'</span> : columns_to_use&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># np.nonzero</span></span><br><span class="line">train_nz = np.log1p(df_train.values.flatten())</span><br><span class="line">train_nz = train_nz[np.nonzero(train_nz)]</span><br><span class="line">plt.hist(train_nz, bins=<span class="number">50</span>)</span><br></pre></td></tr></table></figure>
<h4 id="重复Duplicated"><a href="#重复Duplicated" class="headerlink" title="重复Duplicated"></a>重复Duplicated</h4><h4 id="缺失Missing"><a href="#缺失Missing" class="headerlink" title="缺失Missing"></a>缺失Missing</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df_train.isnull.values.any()</span><br></pre></td></tr></table></figure>
<h4 id="异常Outliers"><a href="#异常Outliers" class="headerlink" title="异常Outliers"></a>异常Outliers</h4>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mirokule.github.io/2018/06/04/ML-AutoEncoder/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Miles">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gate of Babylon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/04/ML-AutoEncoder/" itemprop="url">自编码器</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-04T14:07:00+08:00">
                2018-06-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  524
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="单个自编码器"><a href="#单个自编码器" class="headerlink" title="单个自编码器"></a>单个自编码器</h4><p>自编码器可以理解为一个试图去还原其原始输入的系统，如下图所示：<br><img src="./img/auto_encoder_1.jpg"></p>
<p>自编码器的目的是，让输出$\tilde{x}$尽可能复现输入x。<br>对应神经网络中，输出层的节点数应该和输入层相同。<br><img src="./img/auto_encoder_2.jpg"></p>
<p>损失函数可以是二次误差或者交叉熵。<br>从数据维度看，有以下两种情况：</p>
<ul>
<li>n &gt; p: 隐藏层维度小于输入维度。若损失为二次误差，且变换为线性时，该网络等价于PCA。</li>
<li>n &lt; p: 隐藏层维度大于输入维，此时便是”稀疏自编码器“</li>
</ul>
<h4 id="堆叠自编码器"><a href="#堆叠自编码器" class="headerlink" title="堆叠自编码器"></a>堆叠自编码器</h4><p>单个自编码器的训练结束时，可以将输出层去掉，只保留有用的隐藏层。<br><img src="./img/auto_encoder_3.jpg"></p>
<p>得到X的特征表达h后，可以将其当做新的输入，再训练一个新的编码器。<br>将多个自编码器串联之后，称为堆叠自编码器(Stacked Auto-Encoder,SAE):<br><img src="./img/auto_encoder_4.jpg"></p>
<h4 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h4><ol>
<li><p>简单自编码器</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Dense</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line">encoding_dim = <span class="number">32</span></span><br><span class="line"></span><br><span class="line">input_img = Input(shape=(<span class="number">784</span>,))</span><br><span class="line">encoded = Dense(encoding_dim, activation=<span class="string">'relu'</span>)(input_img)</span><br><span class="line">decoded = Dense(<span class="number">784</span>, activation=<span class="string">'sigmoid'</span>)(encoded)</span><br><span class="line"></span><br><span class="line"><span class="comment"># models</span></span><br><span class="line">autoencoder = Model(input_img, decoded)</span><br><span class="line">encoder = Model(input_img, encoded)</span><br><span class="line"></span><br><span class="line"><span class="comment"># compile</span></span><br><span class="line">autoencoder.compile(optimizer=<span class="string">'adadelta'</span>, loss=<span class="string">'binary_crossentropy'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>深度自编码器</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">input_img = Input(shape=(<span class="number">784</span>,))</span><br><span class="line">encoded = Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>)(input_img)</span><br><span class="line">encoded = Dense(<span class="number">64</span>, activaiton=<span class="string">'relu'</span>)(encoded)</span><br><span class="line">encoded = Dense(<span class="number">32</span>, activation=<span class="string">'relu'</span>)(encoded)</span><br><span class="line"></span><br><span class="line">decoded = Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>)(encoded)</span><br><span class="line">decoded = Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>)(decoded)</span><br><span class="line">decoded = Dense(<span class="number">784</span>, activation=<span class="string">'sigmoid'</span>)(decoded)</span><br><span class="line"></span><br><span class="line">autoencoder = Model(input_img, decoded)</span><br><span class="line">autoencoder.compile(optimizer=<span class="string">'adadelta'</span>, loss=<span class="string">'binary_crossentropy'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>卷积自编码器</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">input_img = Input(shape=(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">x = Conv2D(<span class="number">16</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>)(input_img)</span><br><span class="line">x = MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), padding=<span class="string">'same'</span>)(x)</span><br><span class="line">x = Conv2D(<span class="number">8</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>)(x)</span><br><span class="line">x = MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), padding=<span class="string">'same'</span>)(x)</span><br><span class="line">x = Conv2D(<span class="number">8</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>)(x)</span><br><span class="line">encoded = MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), padding=<span class="string">'same'</span>)(x)</span><br><span class="line"></span><br><span class="line">x = Conv2D(<span class="number">8</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>)(encoded)</span><br><span class="line">x = UpSampling2D((<span class="number">2</span>,<span class="number">2</span>))(x)</span><br><span class="line">x = Conv2D(<span class="number">8</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>)(x)</span><br><span class="line">x = UpSamping2D((<span class="number">2</span>,<span class="number">2</span>))(x)</span><br><span class="line">x = Conv2D(<span class="number">16</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">x= UpSampling((<span class="number">2</span>,<span class="number">2</span>))(x)</span><br><span class="line">decoded = Conv2D(<span class="number">1</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">'sigmoid'</span>, padding=<span class="string">'same'</span>)(x)</span><br><span class="line"></span><br><span class="line">autoencoder = Model(input_img, decoded)</span><br><span class="line">autoencoder.compile(optimizer=<span class="string">'adadelta'</span>, loss=<span class="string">'binary_crossentropy'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>Sequence-to-sequence 自编码器</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">inputs = Input(shape=(timesteps, input_dim))</span><br><span class="line">encoded = LSTM(latent_dim)(inputs)</span><br><span class="line"></span><br><span class="line">decoded = RepeatVector(timesteps)(encoded)</span><br><span class="line">decoded = LSTM(input_dim, return_sequences=<span class="keyword">True</span>)(decoded)</span><br><span class="line"></span><br><span class="line">sequence_autoencoder = Model(inputs, decoded)</span><br><span class="line">encoder = Model(inputs, encoded)</span><br></pre></td></tr></table></figure>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mirokule.github.io/2018/06/04/DL-DBN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Miles">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gate of Babylon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/04/DL-DBN/" itemprop="url">深度信念网络</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-04T11:15:25+08:00">
                2018-06-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  181
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>深度信念网络(Deep Belief Network)是一个概率生成模型，由多个限制玻尔兹曼机层组成。<br>生成模型建立了观察数据和标签之间的联合分布，对P(OBservation|Label)和P(Label|Observation)都做了评估，而判别模型只评估了后者。<br>一个典型的DBN网络结构如图所示：<br><img src="./img/DBN_1.png"></p>
<h4 id="训练方法"><a href="#训练方法" class="headerlink" title="训练方法"></a>训练方法</h4><p><img src="./img/DBN_2.png"></p>
<p>训练时采用逐层无监督学习来训练参数。<br>首先，将输入层和第一个隐藏层当做一个RBM，训练出这个RBM的参数；<br>然后，固定h1的参数，将第二个隐藏层当做RBM，继续训练参数；<br>以此类推，逐层训练参数并固定。<br>具体算法如下：<br><img src="./img/DBN_3.png"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mirokule.github.io/2018/06/04/ML-RBM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Miles">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gate of Babylon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/04/ML-RBM/" itemprop="url">受限玻尔兹曼机</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-04T10:57:21+08:00">
                2018-06-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  258
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>受限玻尔兹曼机(Resticted Boltzmann Machine, RBM)由两层神经网络构成。<br>第一层是可见层/输入层，第二层是隐藏层。<br>两层之间可以通信，层内不可以通信。<br><img src="./img/RBM_1.jpeg"></p>
<p>前向传播和神经网络是一样的，将输入乘以权重W，加上偏置项b1，再通过激活单元得到输出。<br>$$ a = f(WX + b) $$</p>
<p>但是在重建阶段，会以隐藏层的输出作为输入，乘以共享权重W，加上新的偏置项b2，来试图还原可见层的输入X。<br><img src="./img/RBM_2.jpeg"></p>
<p>这种重建称为生成学习，不同于分类器执行的判别学习。<br>判别学习将输入映射到标签上，在样本数据和标签之间绘制条件概率；<br>生成学习得到的是输入的一种概率分布。</p>
<p>RBM使用KL散度来度量真实输入和还原输入的分布的差异。<br>RBM的优化算法试图最小化这种差异，使两种概率分布逐渐重合。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mirokule.github.io/2018/06/04/ML-KLDivergence/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Miles">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gate of Babylon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/04/ML-KLDivergence/" itemprop="url">KL散度</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-04T10:01:44+08:00">
                2018-06-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  479
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>KL散度(Kullback-Leibler Divergence)是一种量化两种概率分布P和Q之间差异的方式，又称作相对熵。</p>
<p><strong>熵(Entropy)</strong><br>对概率分布P，信息度量单位熵的公式如下：<br>$$ H = -\sum^{N}_{i=1} p(x_i) \cdot log\,p(x_i) $$</p>
<p>1.上式的Log没有确定底数，可以是2、e或者10.<br>如果以2为底数，则熵值H可以看做是编码信息所需要的最少二进制位个数。<br>但是熵值H并没有给出编码的最优化方式，即如何使用最少的位数编码。<br>2.熵衡量的是信息的不确定性。<br>如果概率分布P只有1个值，$p(x_i)=1$，那么H=0，不确定性为0；<br>如果有8个值得均匀分布，$p(x_i)=\frac{1}{8}$，以2为底数时，H=3</p>
<p><strong>相对熵</strong><br>如果用概率分布Q来近似概率分布P，那么信息的损失——KL散度定义为：<br>$$ D_{KL}(p \mid\mid q) = \sum_{i=1}^N p(x_i)\cdot(log\, p(x_i) - log\, q(x_i)) = \sum_{i=1}^N p(x_i)\cdot log\frac{ p(x_i)}{q(x_i)} $$</p>
<p>KL散度度量的是一种分布到另一种分布的熵的损失，但<strong>并不是</strong>距离。<br>KL散度不符合对称性，即 从P到Q 和 从Q到P 所损失的信息是不一样的。</p>
<p><strong>交叉熵</strong><br>在给定概率分布P时，使用概率分布Q所指定的策略，来消除系统不确定性，所需要付出的努力大小：<br>$$ C = -\sum^{N}_{i=1} p(x_i) \cdot log\,q(x_i) $$</p>
<p>交叉熵越低，概率分布Q越接近P，所指定的策略就越好。<br>当Q=P时，$q(x_i) = p(x_i)$，交叉熵=信息熵，此时的策略为最优策略，达到最小值下限。<br>在分类算法中，使用交叉熵作为目标函数，使交叉熵尽可能小，就能使得学习到的概率分布尽可能接近真实分布。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mirokule.github.io/2018/05/30/Python-sklearn-TSNE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Miles">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gate of Babylon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/30/Python-sklearn-TSNE/" itemprop="url">sklearn.manifold.TSNE</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-30T10:39:29+08:00">
                2018-05-30
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  190
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>t-SNE(t-distributed Stochastic Neighbor Embedding)是Embedding的一种，可以将高维数据映射到低维空间，并保持数据的相似性。<br>t-SNE是一种“非线性降维”，通常用来视觉直观验证算法有效性，很少用来降维并后接分类器。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">sklearn</span>.<span class="title">manifold</span>.<span class="title">TSNE</span><span class="params">(n_components=<span class="number">2</span>, perplexity=<span class="number">30.0</span>, early_exaggeration=<span class="number">12.0</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">    learning_rate=<span class="number">200.0</span>, n_iter=<span class="number">1000</span>, n_iter_without_progress=<span class="number">300</span>, min_grad_norm=<span class="number">1e-07</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">    metric=’euclidean’, init=’random’, verbose=<span class="number">0</span>, random_state=None, method=’barnes_hut’, angle=<span class="number">0.5</span>)</span></span></span><br></pre></td></tr></table></figure>
<p>参数</p>
<ul>
<li>n_componets: 降维后的空间维度，默认2</li>
<li>perplexity: 困惑度，最近邻数量，通常5-50，tSNE对该参数不敏感</li>
</ul>
<p>方法</p>
<ul>
<li>fit(X, y=None)</li>
<li>fit_transform(X, y=None)</li>
<li>get_params</li>
<li>set_params()</li>
</ul>
<p>实例<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.manifold <span class="keyword">import</span> TSNE</span><br><span class="line"></span><br><span class="line">X = np.array([[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>], [<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>], [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>], [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]])</span><br><span class="line">X_embedded = TSNE(n_components=<span class="number">2</span>).fit_transform(X)</span><br><span class="line">X_embedded.shape <span class="comment">#(4,2)</span></span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mirokule.github.io/2018/05/28/DL-Optimization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Miles">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gate of Babylon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/28/DL-Optimization/" itemprop="url">神经网络配置与性能提升</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-28T15:02:35+08:00">
                2018-05-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  486
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="激活函数Activation"><a href="#激活函数Activation" class="headerlink" title="激活函数Activation"></a>激活函数Activation</h4><ol>
<li><p>Sigmoid: 现已基本不用，缺点有三 </p>
<ul>
<li>饱和区会杀死梯度</li>
<li>输出0~1全为正，那么梯度全为正负，使w更新方向受限制(所以输入数据mean=0最好)</li>
<li>指数运算开销大</li>
</ul>
</li>
<li><p>Tanh: 解决了Mean=0的问题，仍会杀死梯度、指数运算</p>
</li>
<li>Relu: 收敛速度约6倍，没有mean=0，会有神经元“死亡”；一般为首选</li>
<li>Leaky Relu、Max Out、ELU: 可尝试</li>
</ol>
<h4 id="初始化Initialization"><a href="#初始化Initialization" class="headerlink" title="初始化Initialization"></a>初始化Initialization</h4><ol>
<li>全为0，所有节点结果相同；太小，梯度消失；太大，网络饱和</li>
<li>Xavier/Glorot: 使输入输出方差相同，适合搭配tanh</li>
<li>He: 方差除2，适合搭配relu</li>
</ol>
<h4 id="优化器Optimizer"><a href="#优化器Optimizer" class="headerlink" title="优化器Optimizer"></a>优化器Optimizer</h4><ol>
<li>SGD: 经典方法，通常较慢</li>
<li>动量: 收敛速度加快，但容易over shooting，即步长降低得慢</li>
<li>RMSProp: 各方向步长尽量均衡</li>
<li>Adam: RMSProp + 动量，一般为首选</li>
</ol>
<h4 id="损失函数Loss"><a href="#损失函数Loss" class="headerlink" title="损失函数Loss"></a>损失函数Loss</h4><ol>
<li>铰链Hinge: 主要用于SVM</li>
<li>互熵Cross Entropy Loss: 用于Logistic、Softmax分类</li>
<li>平方Square Loss: 用于最小二乘法(OLS)</li>
<li>指数Exponential Loss: 用于Adaboost等集成学习算法</li>
</ol>
<h4 id="克服overfitting"><a href="#克服overfitting" class="headerlink" title="克服overfitting"></a>克服overfitting</h4><ol>
<li>Batch Normalization一般为首选，效果不好时再考虑其他手段；通常在Activation层之前。</li>
<li>Dropout相当于内部集成，注意测试时不用drop，得分要乘以比例p</li>
<li>Data Augmentation: 生成更多训练数据</li>
</ol>
<p>Q: 如何识别？<br>A: 画出学习曲线，观察训练误差和验证误差</p>
<h4 id="超参数Hyperparameters"><a href="#超参数Hyperparameters" class="headerlink" title="超参数Hyperparameters"></a>超参数Hyperparameters</h4><ol>
<li>Learning Rate是最重要的超参数，没有之一。<br>网格搜索同样适用于深层神经网络的超参调整，每次选用少量的epoch测试。</li>
<li>Learning Rate Decay是二阶超参，不需要一开始就引入。<br>注意Learning Rate Decay和Adam的原理相悖，通常不兼容。</li>
</ol>
<h4 id="模型集成Ensemble"><a href="#模型集成Ensemble" class="headerlink" title="模型集成Ensemble"></a>模型集成Ensemble</h4><p>训练10个参数不同的模型，对预测结果投票，期望提升2%</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mirokule.github.io/2018/05/19/ML-FeatureImportance/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Miles">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gate of Babylon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/19/ML-FeatureImportance/" itemprop="url">特征重要性评估(Feature Importance Evaluation)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-19T15:12:27+08:00">
                2018-05-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  446
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>特征对目标变量预测的相对重要性，可以通过决策树中使用特征作为决策节点的相对顺序来评估。<br>决策树顶部使用的特征，将对更多样本的最终预测决策做出贡献。<br>因此，可以通过每个特征对最终预测做出贡献的样本比例，来评估该特征的重要性。</p>
<p>通过对多个随机树中的预期贡献率取平均，可以减少这种估计的方差。</p>
<p>sklearn.ensemble模块包含两个基于随机决策树的平均算法：Random Forest 和 Extra-Tress.<br>这两种算法都是在构造过程中引入随机性来创建一组不同的分类器。</p>
<h4 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h4><p>实例一: 特征重要性二维可视化<br><img src="/img/featureImportance_1.png" width="500"><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.dataset <span class="keyword">import</span> fetch_olivetti_faces</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> ExtraTreesClassifier</span><br><span class="line"></span><br><span class="line">n_jobs=<span class="number">1</span> <span class="comment">#单核</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">data = fetch_oliveetti_faces()</span><br><span class="line">X = data.images.reshape((len(data.images),<span class="number">-1</span>))</span><br><span class="line">y = data.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建学习器</span></span><br><span class="line">forest = ExtraTreesClassifier(n_estimators=<span class="number">1000</span>, max_features=<span class="number">128</span>, n_jobs=n_jobs)</span><br><span class="line">forest.fit(X,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出特征重要性</span></span><br><span class="line">importances = forest.feature_importances_</span><br><span class="line">importances = importances.reshape(data.image[<span class="number">0</span>].shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line">plt.matshow(importances. cmap=plt.cm.hot)</span><br><span class="line">plt.title(<span class="string">"Pixel importances with forests of trees"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<p>实例二：特征重要性一维可视化<br><img src="/img/featureImportance_2.png" width="600"><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classification</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> ExtraTreesClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成测试数据</span></span><br><span class="line">X,y = make_classification(n_samples=<span class="number">1000</span>, n_features=<span class="number">10</span>, n_informative=<span class="number">3</span>, n_classes=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选取学习器</span></span><br><span class="line">forest = ExtraTreesClassifier(n_estimators=<span class="number">250</span>, random_state=<span class="number">0</span>)</span><br><span class="line">forest.fit(X,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出特征重要性</span></span><br><span class="line">importances = forest.feature_importances_</span><br><span class="line">std = np.std([tree.feature_importances_ <span class="keyword">for</span> tree <span class="keyword">in</span> forest.estimators_], axis=<span class="number">0</span>)</span><br><span class="line">indices = np.argsort(importances)[::<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印</span></span><br><span class="line">print(<span class="string">"Feature ranking:"</span>)</span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> range(X.shape[<span class="number">1</span>]):</span><br><span class="line">    print(<span class="string">"%d. feature %d (%f)"</span> % (f+<span class="number">1</span>, indices[f], importances[indices[f]]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.title(<span class="string">"Feature importances"</span>)</span><br><span class="line">plt.bar(range(X.shape[<span class="number">1</span>]), importances[indices], color=<span class="string">'r'</span>, yerr=std[indices], align=<span class="string">'center'</span>)</span><br><span class="line">plt.xticks(range(X.shape[<span class="number">1</span>]), indices)</span><br><span class="line">plt.xlim([<span class="number">-1</span>, X.shape[<span class="number">1</span>]])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mirokule.github.io/2018/05/19/ML-MissingValues/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Miles">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gate of Babylon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/19/ML-MissingValues/" itemprop="url">缺失值处理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-19T14:23:20+08:00">
                2018-05-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  573
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>缺失值的处理方法分为三类：</p>
<ul>
<li>删除：删除含有缺失字段的样本</li>
<li>修补：有多种方法</li>
<li>不处理：直接使用不完整数据作为输入</li>
</ul>
<h3 id="修补方法"><a href="#修补方法" class="headerlink" title="修补方法"></a>修补方法</h3><ol>
<li><p>人工修补(filling manually)<br>由了解数据的用户填写，偏离最小，填充效果最好。<br>成本巨大，当数据规模大时不适用。</p>
</li>
<li><p>特殊值(Special values)<br>将缺失值当做一种特殊的属性值来处理，不同于其他的任何属性值。例如’unknown’.<br>可能导致严重的数据偏离。一般不推荐使用。</p>
</li>
<li><p>均值填充(Mean/Mode Completer)<br>用现存数据的多数信息来推测缺失值。<br>数值型字段，使用其他样本在该字段上的均值；<br>非数值型字段，使用出现次数最多的值。</p>
</li>
<li><p>热卡填充(Hot deck imputation)<br>在完整数据中找到一个最相似的对象，然后用这个最相似对象的值填充。<br>缺点在于难以定义相似标准。</p>
</li>
<li><p>聚类填充(clustering imputation)<br>首先确定与缺失样本距离最近的k个样本，然后用k个样本的均值填充。</p>
</li>
<li><p>所有可能的值填充(all possible values)<br>使用空缺属性值的所有可能的取值来填充。<br>计算代价大，可能的测试方案多。</p>
</li>
<li><p>组合完整化方法(Combinatorial Completer)<br>使用所有可能的属性取值来试，从中选择最好的一个作为填补的属性值。</p>
</li>
<li><p>回归(Regression)<br>基于完整的数据集，建立回归方程。将缺失记录的已知属性值代入方程，得到缺失值的回归估计值。<br>当变量不是线性相关时，会导致有偏差的估计。</p>
</li>
<li><p>极大似然估计(Max Likelihood)<br>通过观察数据的边际分布可以对未知参数进行极大似然估计。<br>最常采用的计算方法是期望值最大化(Expectation Maximization, EM)。<br>适用大样本，计算很复杂。</p>
</li>
<li><p>多重插补(Multiple Imputation)<br>来源于贝叶斯估计，认为待修补的值是随机的，来自于已观测到的值。<br>具体实践上通常是估计出待插补的值，然后加上不同的噪声，形成多组可选插补值。</p>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mirokule.github.io/2018/05/19/Python-pandas-DataFrame/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Miles">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gate of Babylon">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/19/Python-pandas-DataFrame/" itemprop="url">pandas.DataFrame</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-19T11:12:59+08:00">
                2018-05-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  449
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>class pandas.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)</p>
<h3 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h3><p><strong>数据容量</strong></p>
<ul>
<li>ndims: 维度</li>
<li>shape: 尺寸(h,w,b)</li>
<li>size: 元素个数=h×w×b</li>
<li>dtypes: 元素类型</li>
</ul>
<p><strong>表格组成</strong></p>
<ul>
<li>axes: 横纵轴的列表</li>
<li>index: 行标签</li>
<li>columns: 列标签</li>
<li>values: 值的numpy数组</li>
</ul>
<p><strong>数据选取</strong></p>
<ul>
<li>at: 根据行列名称选取单个元素</li>
<li>iat: 根据行列序号选取单个元素</li>
<li>loc: 根据行列名称\Boolean序列选取内容</li>
<li>iloc: 根据行列序号选取内容</li>
</ul>
<p><strong>其他</strong></p>
<ul>
<li>T: 转置</li>
<li>empty: 是否为空</li>
</ul>
<h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p><strong>重复数据</strong></p>
<ul>
<li>duplicated(): 返回boolean序列</li>
<li>drop_duplicates()</li>
</ul>
<p><strong>缺失值</strong></p>
<ul>
<li>isna(), isnull()</li>
<li>notna(), notnull()</li>
<li>dropna()</li>
<li>fillna()</li>
</ul>
<p><strong>添加删除</strong></p>
<ul>
<li>append(): 添加行</li>
<li>insert(): 插入列</li>
<li>drop(): 删除行或列 </li>
</ul>
<p><strong>替换更新</strong></p>
<ul>
<li>replace(): 用新值替换旧的</li>
<li>update(): 用另一个dataframe中的元素更新</li>
</ul>
<p><strong>重命名行列标签</strong></p>
<ul>
<li>rename(), rename_axis()</li>
<li>add_prefix(), add_suffix(): 给标签添加前缀\后缀</li>
</ul>
<p><strong>查看内容</strong></p>
<ul>
<li>head(n), tail(n)</li>
<li>info(): 简明摘要</li>
<li>describe(): 统计信息</li>
</ul>
<p><strong>统计函数</strong></p>
<ul>
<li>sum()</li>
<li>prod(), product()</li>
<li>std(), var()</li>
<li>skew(), kurt(), kurtosis()</li>
<li>max(), min(), mean(), mode(), median()</li>
</ul>
<p><strong>单表运算</strong></p>
<ul>
<li>clip(), clip_lower(), clipupper()</li>
<li>round()</li>
<li>abs()</li>
</ul>
<p><strong>双表运算</strong></p>
<ul>
<li>add(): 两个dataframe的元素相加</li>
<li>sub(), subtract()</li>
<li>dot(): 矩阵乘法</li>
<li>mul(), multiply(): 元素乘法</li>
<li>div, divide()</li>
<li>mod(): 取模</li>
<li>corrwith(): 相关性</li>
</ul>
<p><strong>双表合并</strong></p>
<ul>
<li>merge()</li>
<li>join()</li>
<li>combine()</li>
<li>combine_first()</li>
</ul>
<p><strong>重排</strong></p>
<ul>
<li>squeeze()</li>
<li>stack()</li>
<li>unstack()</li>
<li>pivot</li>
<li>pivot_table()</li>
</ul>
<p><strong>排序抽样</strong></p>
<ul>
<li>sort_index()</li>
<li>sort_values()</li>
<li>sample(n): 抽样样本</li>
<li>nlargest(n), nsmallest(n): 根据指定列排序后，返回最大/最小的n行</li>
</ul>
<p><strong>迭代器</strong></p>
<ul>
<li>items(), iteritems(): (</li>
<li>iterrows()</li>
</ul>
<p><strong>绘图</strong></p>
<ul>
<li>plot()</li>
<li>boxplot()</li>
<li>hist()</li>
</ul>
<p><strong>存储</strong></p>
<ul>
<li>to_csv()</li>
<li>to_excel()</li>
<li>to_hdf()</li>
</ul>
<h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p><strong>插入列</strong><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.DataFrame(columns=[<span class="string">'A'</span>,<span class="string">'B'</span>], data=[[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 直接使用新列名，只能在最右侧添加一列</span></span><br><span class="line">df[<span class="string">'C'</span>] = [<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用pd.concat，不能指定位置，可以添加多列</span></span><br><span class="line">pd.concat([df, pd.DataFrame(columns=[<span class="string">'D'</span>,<span class="string">'E'</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用reindex，可以指定位置，可以添加多列</span></span><br><span class="line">df.reindex(columns=list(<span class="string">'BCADE'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用insert()</span></span><br><span class="line">df.insert(loc, column, value, allow_duplicates=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/16/">16</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.png"
                alt="Miles" />
            
              <p class="site-author-name" itemprop="name">Miles</p>
              <p class="site-description motion-element" itemprop="description">万人迷</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">320</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">51</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/mirokule" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:miles.miro@gmail.com" target="_blank" title="E-Mail">
                    
                      <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            
          </div>

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.kaggle.com/" title="Kaggle" target="_blank">Kaggle</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://unity3d.com/" title="Unity" target="_blank">Unity</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.apple.com/swift/" title="Swift" target="_blank">Swift</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2015 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">M.M.Tech</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">121.0k</span>
  
</div>










        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
